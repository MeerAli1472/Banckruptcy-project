{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85613770",
   "metadata": {},
   "source": [
    "# 5.1. Working with JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e53e2",
   "metadata": {},
   "source": [
    "In this project, we'll be looking at tracking corporate bankruptcies in Poland. To do that, we'll need to get data that's been stored in a `JSON` file, explore it, and turn it into a DataFrame that we'll use to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461a653",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "## Open\n",
    "The first thing we need to do is access the file that contains the data we need. We've done this using multiple strategies before, but this time around, we're going to use the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9e9d3",
   "metadata": {},
   "source": [
    "**Task 5.1.1:** Open a terminal window and navigate to the directory where the data for this project is located.\n",
    "\n",
    "\n",
    "As we've seen in our other projects, datasets can be large or small, messy or clean, and complex or easy to understand. Regardless of how the data looks, though, it needs to be saved in a file somewhere, and when that file gets too big, we need to *compress* it. Compressed files are easier to store because they take up less space. If you've ever come across a `ZIP` file, you've worked with compressed data. \n",
    "\n",
    "The file we're using for this project is compressed, so we'll need to use a file utility called `gzip` to open it up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9471263",
   "metadata": {},
   "source": [
    "- go to terminal access the data directory and use gzip -dkf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10009079",
   "metadata": {},
   "source": [
    "**Task 5.1.2:** In the terminal window, locate the data file for this project and decompress it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data\n",
    "gzip -dkf poland-bankruptcy-data-2009.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a7cb9",
   "metadata": {},
   "source": [
    "# Explore\n",
    "Now that we've decompressed the data, let's take a look and see what's there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b101257",
   "metadata": {},
   "source": [
    "**Task 5.1.3:** In the terminal window, examine the first 10 lines of `poland-bankruptcy-data-2009.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73779dd1",
   "metadata": {},
   "source": [
    "**Task 5.1.4:** Open `poland-bankruptcy-data-2009.json` by opening the `data` folder to the left and then double-clicking on the file. ðŸ‘ˆ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7074a4",
   "metadata": {},
   "source": [
    "How is the data organized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c461a7",
   "metadata": {},
   "source": [
    "Curly brackets? Key-value pairs? It looks similar to a Python dictionary. It's important to note that JSON is not _exactly_ the same as a dictionary, but a lot of the same concepts apply. Let's try reading the file into a DataFrame and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71172486",
   "metadata": {},
   "source": [
    "**Task 5.1.5:** Load the data into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/poland-bankruptcy-data-2009.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b4fb8",
   "metadata": {},
   "source": [
    "Hmmm. It looks like something went wrong, and we're going to have to fix it. Luckily for us, there's an error message to help us figure out what's happening here:\n",
    "\n",
    "<code style=\"background-color:#FEDDDE;\"><span style=\"color:#E45E5C\">ValueError</span>: Mixing dicts with non-Series may lead to ambiguous ordering.\n",
    "</code>\n",
    "\n",
    "What should we do? That error sounds serious, but the world is big, and we can't possibly be the first people to encounter this problem. When you come across an error, copy the message into a search engine and see what comes back. You'll get lots of results. The web has lots of places to look for solutions to problems like this one, and [Stack Overflow](https://stackoverflow.com/) is one of the best. [Click here to check out a possible solution to our problem.](https://stackoverflow.com/questions/57018859/valueerror-mixing-dicts-with-non-series-may-lead-to-ambiguous-ordering)\n",
    "\n",
    "There are three things to look for when you're browsing through solutions on Stack Overflow. \n",
    "\n",
    "1. **Context:** A good question is specific; if you click through that link, you'll see that the person asks a **specific** question, gives some relevant information about their OS and hardware, and then offers the code that threw the error. That's important, because we need...\n",
    "2. **Reproducible Code:** A good question also includes enough information for you to reproduce the problem yourself. After all, the only way to make sure the solution actually applies to your situation is to see if the code in the question throws the error you're having trouble with! In this case, the person included not only the code they used to get the error, but the actual error message itself. That would be useful on its own, but since you're looking for an actual solution to your problem, you're really looking for...\n",
    "3. **An answer:** Not every question on Stack Overflow gets answered. Luckily for us, the one we've been looking at did. There's a big green check mark next to the first solution, which means that the person who asked the question thought that solution was the best one.\n",
    "\n",
    "Let's try it and see if it works for us too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf3817",
   "metadata": {},
   "source": [
    "**Task 5.1.6:** Using a context manager, open the file `poland-bankruptcy-data-2009.json` and load it as a dictionary with the variable name `poland_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b200fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and load JSON\n",
    "with open(\"data/poland-bankruptcy-data-2009.json\",\"r\") as read_file:\n",
    "    poland_data = json.load(read_file)\n",
    "\n",
    "print(type(poland_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b142c0",
   "metadata": {},
   "source": [
    "Okay! Now that we've successfully opened up our dataset, let's take a look and see what's there, starting with the keys. Remember, the keys in a dictionary are categories of things in a dataset.WQU WorldQuant University Applied Data Scienc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c359ea9b",
   "metadata": {},
   "source": [
    "**Task 5.1.7:** Print the keys for `poland_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print `poland_data` keys\n",
    "poland_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb229c",
   "metadata": {},
   "source": [
    "schema tells us how the data is structured, metadata tells us where the data comes from, and data is the data itself.\n",
    "\n",
    "Now let's take a look at the values. Remember, the values in a dictionary are ways to describe the variable that belongs to a key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18636523",
   "metadata": {},
   "source": [
    "**Task 5.1.8:** Explore the values associated with the keys in `poland_data`. What do each of them represent? How is the information associated with the `\"data\"` key organized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ef381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Exploring `poland_data`\n",
    "# poland_data[\"metadata\"]\n",
    "# poland_data[\"schema\"].keys()\n",
    "poland_data[\"data\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69f268",
   "metadata": {},
   "source": [
    "This dataset includes all the information we need to figure whether or not a Polish company went bankrupt in 2009. There's a bunch of features included in the dataset, each of which corresponds to some element of a company's balance sheet. You can explore the features by looking at the data dictionary. Most importantly, we also know whether or not the company went bankrupt. That's the last key-value pair.\n",
    "\n",
    "Now that we know what data we have for each company, let's take a look at how many companies there are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101be0e",
   "metadata": {},
   "source": [
    "**Task 5.1.9:** Calculate the number of companies included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b296273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of companies\n",
    "len(poland_data[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642eeaa5",
   "metadata": {},
   "source": [
    "**Task 5.1.10:** Calculate the number of features associated with `\"company_1\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2a6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of features\n",
    "len(poland_data[\"data\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dec7a8",
   "metadata": {},
   "source": [
    "Since we're dealing with data stored in a JSON file, which is common for semi-structured data, we can't assume that all companies have the same features. So let's check!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcbcf5",
   "metadata": {},
   "source": [
    "**Task 5.1.11:** Iterate through the companies in `poland_data[\"data\"]` and check that they all have the same number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9909950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through companies\n",
    "for item in poland_data[\"data\"]:\n",
    "    if len(item) != 66:\n",
    "        print(\"ALERT!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef748357",
   "metadata": {},
   "source": [
    "It looks like they do!\n",
    "\n",
    "Let's put all this together. First, open up the compressed dataset and load it directly into a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791810c2",
   "metadata": {},
   "source": [
    "**Task 5.1.12:** Using a context manager, open the file `poland-bankruptcy-data-2009.json.gz` and load it as a dictionary with the variable name `poland_data_gz`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8424a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open compressed file and load contents\n",
    "with gzip.open(\"data/poland-bankruptcy-data-2009.json.gz\",\"r\") as read_file:\n",
    "    poland_data_gz = json.load(read_file)\n",
    "\n",
    "print(type(poland_data_gz))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47f72c",
   "metadata": {},
   "source": [
    "Since we now have two versions of the dataset â€” one compressed and one uncompressed â€” we need to compare them to make sure they're the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca095d7",
   "metadata": {},
   "source": [
    "**Task 5.1.13:** Explore `poland_data_gz` to confirm that is contains the same data as `data`, in the same format. <span style=\"display: none\">WorldQuant University Canary</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore `poland_data_gz`\n",
    "print(poland_data_gz.keys())\n",
    "print(len(poland_data_gz[\"data\"]))\n",
    "print(len(poland_data_gz[\"data\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f13741f",
   "metadata": {},
   "source": [
    "Looks good! Now that we have an uncompressed dataset, we can turn it into a DataFrame using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea84219",
   "metadata": {},
   "source": [
    "**Task 5.1.14:** Create a DataFrame `df` that contains the all companies in the dataset, indexed by `\"company_id\"`. Remember the principles of *tidy data* that you learned in Project 1, and make sure your DataFrame has shape `(9977, 65)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame().from_dict(poland_data_gz[\"data\"]).set_index(\"company_id\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29651091",
   "metadata": {},
   "source": [
    "# Import\n",
    "Now that we have everything set up the way we need it to be, let's combine all these steps into a single function that will decompress the file, load it into a DataFrame, and return it to us as something we can use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efad8c",
   "metadata": {},
   "source": [
    "**Task 5.1.15:** Create a `wrangle` function that takes the name of a compressed file as input and returns a tidy DataFrame. After you confirm that your function is working as intended, submit it to the grader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(filename):\n",
    "    with gzip.open(filename,\"r\") as f:\n",
    "        data = json.load(f)\n",
    "        df = pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d55b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(\"data/poland-bankruptcy-data-2009.json.gz\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
